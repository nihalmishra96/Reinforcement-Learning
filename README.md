# Reinforcement-Learning


In Part 1, a defined environment called "Loveworld" is introduced, which is a 4x4 grid environment. The objective is for a boy to navigate through the grid, encountering various rewards and reaching the highest reward point. Safety in AI is also discussed, highlighting the importance of monitoring the environment and implementing constraints for allowed actions.

Parts 2 and 3 focus on tabular methods used to solve problems, specifically SARSA and Q-Learning algorithms. The update functions and advantages/disadvantages of each algorithm are explained. Hyperparameter tuning is performed for both algorithms, varying the number of episodes and discount factors.

The results show the gradual reduction of the exploration parameter over time and the convergence of the total rewards, indicating the learning progress of the agent. The report also includes plots for different hyperparameter settings and compares the reward dynamics of SARSA and Q-Learning. The best parameters for both algorithms are identified.

This project was completed as part of the Assignment for CSE 4/574: Introduction to Machine Learning at the University at Buffalo. Credit for the assignment goes to Professor Alina Vereshchaka.

A detailed report of this project has also been submitted for a deeper understanding of the work done in this repository.
